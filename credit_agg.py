# -*- coding: utf-8 -*-
"""credit_Agg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O2aJXTNMYaILNO6-TZCbSzMN-rvfSlPW
"""

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
pd.set_option("max_columns",0)
path =  os.getcwd()

df_inst = pd.read_csv('./csv/installments_payments.csv')
df_pos = pd.read_csv('./csv/POS_CASH_balance.csv')
df_prev = pd.read_csv('./csv/previous_application.csv')
df_bu = pd.read_csv('./csv/bureau.csv')
df_app = pd.read_csv('./csv/application_train.csv')

"""### **Unite the Home Credit files:**"""

# num of unique SK_ID_PREV in each file
print(df_inst['SK_ID_PREV'].nunique(),df_pos['SK_ID_PREV'].nunique(),df_prev['SK_ID_PREV'].nunique())
# convet to set
set_inst = set(df_inst['SK_ID_PREV'])
set_pos = set(df_pos['SK_ID_PREV'])
set_prev = set(df_prev['SK_ID_PREV'])
# intersection of sets
set_inter_idx = set_inst.intersection(set_pos, set_prev)
# num of SK_ID_PREV in the intersection set
print(len(set_inter_idx))
# create new files
df_inst_new = df_inst[df_inst['SK_ID_PREV'].isin(set_inter_idx)]
df_pos_new = df_pos[df_pos['SK_ID_PREV'].isin(set_inter_idx)]
df_prev_new = df_prev[df_prev['SK_ID_PREV'].isin(set_inter_idx)]

"""### **application_train.csv**"""

#the columns that we decided that are relevant to our model
df = df_app
df_select1 = df.iloc[:, 0:19]
df_select1.drop(['NAME_TYPE_SUITE', 'REGION_POPULATION_RELATIVE',  'NAME_CONTRACT_TYPE', 'AMT_GOODS_PRICE'], axis=1, inplace=True)
df_select2 = df.iloc[:, 31]
df_select3 = df.iloc[:, -27:-26]
df_selected = pd.concat([df_select1, df_select2, df_select3], axis=1)

df_selected.columns

# Categorial Reduction - unified analogous categories in 4 features:
# NAME_INCOME_TYPE== NAME_EDUCATION_TYPE==  NAME_FAMILY_STATUS==  NAME_HOUSING_TYPE
name_types = {'Working':'Working',
              'Commercial associate':'Commercial associate',
              'Pensioner':'Pensioner',
              'State servant':'Working',
              'Unemployed':'Unemployed',
              'Student':'Unemployed',
              'Businessman':'Commercial associate',
              'Maternity leave':'Working'}
df_selected.loc[:, 'NAME_INCOME_TYPE'] = df_selected.NAME_INCOME_TYPE.replace(name_types)

education_types = {'Secondary / secondary special':'Secondary',
              'Higher education':'Higher education',
              'Incomplete higher':'Incomplete higher',
              'Lower secondary':'Secondary',
              'Academic degree':'Higher education'}
df_selected.loc[:, 'NAME_EDUCATION_TYPE'] = df_selected.NAME_EDUCATION_TYPE.replace(education_types)

family_status = {'Married':'Married',
              'Single / not married':'not married',
              'Civil marriage':'Married',
              'Separated':'not married',
              'Widow':'Widow',
              'Unknown':'Married'}
df_selected.loc[:, 'NAME_FAMILY_STATUS'] = df_selected.NAME_FAMILY_STATUS.replace(family_status)

housing_type = {'House / apartment':'House / apartment',
              'With parents':'With parents',
              'Municipal apartment':'Municipal apartment',
              'Rented apartment':'Rented apartment',
              'Office apartment':'Rented apartment',
              'Co-op apartment':'House / apartment'}
df_selected.loc[:, 'NAME_HOUSING_TYPE'] = df_selected.NAME_HOUSING_TYPE.replace(housing_type)

# Binary Features = converted to 0,1
gender = {'M':0, 'F':1, 'XNA': 1}
df_selected.loc[:, 'CODE_GENDER'] = df_selected.CODE_GENDER.replace(gender)

car = {'Y':0, 'N':1}
df_selected.loc[:, 'FLAG_OWN_CAR'] = df_selected.FLAG_OWN_CAR.replace(car)

realty = {'Y':0, 'N':1}
df_selected.loc[:, 'FLAG_OWN_REALTY'] = df_selected.FLAG_OWN_REALTY.replace(realty)

# add ROTEM'S code for the last binary column - NAME_CONTRACT_TYPE

city = {1:'A', 2:'B', 3:'C'}
df_selected.loc[:, 'REGION_RATING_CLIENT_W_CITY'] = df_selected.REGION_RATING_CLIENT_W_CITY.replace(city)

df_selected = pd.get_dummies(df_selected, columns=['NAME_HOUSING_TYPE','REGION_RATING_CLIENT_W_CITY','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS'])

df_selected.fillna(0, inplace=True)

df_selected.to_csv('./csv/df_app.csv', index=True)

df_selected

"""### **bureau.csv**"""

df_col = df_bu.drop(['CREDIT_CURRENCY', 'CREDIT_DAY_OVERDUE', 'AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM_LIMIT',
                  'AMT_CREDIT_SUM_OVERDUE', ], axis=1)

semi_final_df = df_col.groupby(['SK_ID_CURR']).agg( 
    BU_NUM_LOAN = pd.NamedAgg(column= 'SK_ID_BUREAU', aggfunc= 'count'),
    BU_SUM_LOAN = pd.NamedAgg(column= 'AMT_CREDIT_SUM', aggfunc= 'sum'),
    BU_SUM_OPEN_DEBT = pd.NamedAgg(column= 'AMT_CREDIT_SUM_DEBT', aggfunc= 'sum'))

index_drop=df_bu.loc[df_bu['CREDIT_ACTIVE'].isin(['Sold', 'Bad debt'])]
df_bu=df_bu.drop(index_drop.index,axis=0)

df_credit_active=df_bu.groupby(['SK_ID_CURR','CREDIT_ACTIVE']).size()/df_bu.groupby('SK_ID_CURR').size()
df1=pd.DataFrame(df_credit_active).reset_index()
df1=df1.rename(columns={0:'percentage'})

df_final1 = pd.crosstab(index=df1.SK_ID_CURR, 
                   columns=df1.CREDIT_ACTIVE,
                   values=df1.percentage,
                   aggfunc='first').fillna(0)

df_final = pd.concat( [semi_final_df, df_final1] ,axis = 1, join='inner')

df_final.to_csv('./csv/df_bureau.csv', index=True)

df_final

"""### **previous_application.csv**"""

df_prev=df_prev_new.drop(columns= [ 'AMT_DOWN_PAYMENT',
                                'AMT_GOODS_PRICE',
                                'WEEKDAY_APPR_PROCESS_START',
                                'HOUR_APPR_PROCESS_START',
                                'FLAG_LAST_APPL_PER_CONTRACT',
                                'NFLAG_LAST_APPL_IN_DAY',
                                'RATE_INTEREST_PRIMARY',
                                'RATE_INTEREST_PRIVILEGED',
                                'NAME_CASH_LOAN_PURPOSE',
                                'NAME_TYPE_SUITE',
                                'NAME_CLIENT_TYPE',
                                'NAME_GOODS_CATEGORY',
                                'NAME_PORTFOLIO',
                                'NAME_PRODUCT_TYPE',
                                'CHANNEL_TYPE',
                                'SELLERPLACE_AREA',
                                'NAME_SELLER_INDUSTRY',
                                'NAME_YIELD_GROUP',
                                'PRODUCT_COMBINATION',
                                'DAYS_FIRST_DRAWING',
                                'DAYS_FIRST_DUE',
                                'DAYS_LAST_DUE_1ST_VERSION',
                                'DAYS_LAST_DUE',
                                'NFLAG_INSURED_ON_APPROVAL',
                                'DAYS_DECISION',
                                'NAME_PAYMENT_TYPE',
                                'CODE_REJECT_REASON',
                                'CNT_PAYMENT',
                                'DAYS_TERMINATION',
                                'NAME_CONTRACT_TYPE'])

mask=df_prev[df_prev['AMT_APPLICATION']==0].index
df_prev=df_prev.drop(mask, axis=0)

#aggregation for name contract status column
contract_status=df_prev.groupby(['SK_ID_CURR','NAME_CONTRACT_STATUS']).size()/df_prev.groupby('SK_ID_CURR').size()
df_contract_status=pd.DataFrame(contract_status).reset_index()
df_contract_status=df_contract_status.rename(columns={0:'percentage'})
df_contract_status_agg = pd.crosstab(index=df_contract_status.SK_ID_CURR, 
                                    columns=df_contract_status.NAME_CONTRACT_STATUS,
                                    values=df_contract_status.percentage,
                                    aggfunc='first').fillna(0)
# Everyone who letf has contract status =  'approved'

df_prev['Percentage_approval_request']= np.divide(df_prev.AMT_CREDIT,df_prev.AMT_APPLICATION)

df_final=df_prev.groupby('SK_ID_CURR').agg(
                          mean_anuuity=('AMT_ANNUITY', 'mean'),
                          mean_percent_approval=('Percentage_approval_request', 'mean'),
                          mean_amt_application=('AMT_APPLICATION','mean'),
                          mean_down_pay=('RATE_DOWN_PAYMENT', 'mean'))

df_final.fillna(0, inplace=True)

df_final.to_csv('./csv/df_prev.csv', index=True)

df_final

"""### **POS_CASH_balance.csv**"""

MONTHS_BALANCE_max=df_pos_new.groupby(['SK_ID_PREV'])['MONTHS_BALANCE'].max()
df=pd.DataFrame()
df['SK_ID_PREV']=MONTHS_BALANCE_max.index
df['MONTHS_BALANCE']=MONTHS_BALANCE_max.values

df_POS_CASH_agg=df.merge(df_pos_new, how='inner', on=['SK_ID_PREV','MONTHS_BALANCE'])
df_POS_CASH_agg=df_POS_CASH_agg.drop(columns=['MONTHS_BALANCE','SK_DPD','CNT_INSTALMENT_FUTURE'])

NAME_CONTRACT_STATUS_drop=['Returned to the store', 'Signed', 'Approved', 'Canceled']

index_drop=df_POS_CASH_agg.loc[df_POS_CASH_agg['NAME_CONTRACT_STATUS'].isin(NAME_CONTRACT_STATUS_drop)]
df_POS_CASH_agg=df_POS_CASH_agg.drop(index_drop.index,axis=0)

Debt_rows=df_POS_CASH_agg[df_POS_CASH_agg['NAME_CONTRACT_STATUS'].isin(['Amortized debt', 'Demand'])]
df_POS_CASH_agg.at[Debt_rows.index,'NAME_CONTRACT_STATUS']='Debt'

df_status=df_POS_CASH_agg.groupby(['SK_ID_CURR','NAME_CONTRACT_STATUS']).size()/df_POS_CASH_agg.groupby('SK_ID_CURR').size()
df1=pd.DataFrame(df_status).reset_index()
df1=df1.rename(columns={0:'percentage'})

df_final = pd.crosstab(index=df1.SK_ID_CURR, 
                   columns=df1.NAME_CONTRACT_STATUS,
                   values=df1.percentage,
                   aggfunc='first').fillna(0)

df_final=df_final.reset_index()

df_final.to_csv('./csv/df_pos.csv', index=True)

"""### **installments_payments.csv:**"""

df_inst_new.sort_values(by = 'SK_ID_PREV').head(10)

df_inst_new['SK_ID_CURR'].nunique()

df_inst_new.info()

# How many prev loans each person took:
df_inst_new.groupby(['SK_ID_CURR'])['SK_ID_PREV'].nunique().value_counts() #.sum() - How many prev loans exist in the data

"""* We can see that most of the people took between 1-6 loans, and at the most 26."""

df_inst_new.isna().sum()

"""* Each person who has missing values in DAYS_ENTRY_PAYMENT column has also missing values in the AMT_PAYMENT column."""

# What is the delay of installment payment? 
# Negative values mean the person had a debt. positive values mean he paid over his due.
# What is the differnece in installment amount payment?
# Negative values mean the person paid in delya. positive values mean he paid precendently the time.
df_inst_new['diff_AMT'] = df_inst_new['AMT_PAYMENT'] - df_inst_new['AMT_INSTALMENT']
df_inst_new['diff_DAYS'] = df_inst_new['DAYS_ENTRY_PAYMENT'] - df_inst_new['DAYS_INSTALMENT']

df_inst_new['diff_DAYS'].value_counts().sort_values()

# What is number of installments each laon has?
a = df_inst_new.groupby('SK_ID_CURR')
b = a['SK_ID_PREV'].value_counts()
b

"""We wish to choose what are the minimum columns needed to fully describe the table content:
* How many loans each person took
* How many instalments in each loans in average
* What is the mean amount of installments payment
* What is the mean delay of installments payment
* What is the mean differnece in installments amount payment
* What is the percentage of unpaid loans per person?
"""

df_inst_new.columns

grouped = df_inst_new.drop(columns = ['NUM_INSTALMENT_VERSION','NUM_INSTALMENT_NUMBER',\
    'DAYS_INSTALMENT','AMT_INSTALMENT']).groupby('SK_ID_CURR', as_index=False)

grouped = grouped.agg(
    NUM_LOANS=('SK_ID_PREV', 'nunique'),
    MEAN_NUM_INSTALMENT = ('SK_ID_PREV', lambda x: x.count().sum()/x.nunique()),
    MEAN_PAYMENT=('AMT_PAYMENT', 'mean'),
    MEAN_PAY_DIFF=('diff_AMT', 'mean'),
    MEAN_PAY_DELAY=('diff_DAYS', 'mean'),
    NUM_UNPAID_LOANS=('DAYS_ENTRY_PAYMENT', lambda x: x.isna().mean())
)

grouped = grouped.round({'MEAN_PAYMENT':0,\
    'MEAN_PAY_DELAY': 0,\
    'MEAN_PAY_DIFF': 0,\
    'MEAN_NUM_INSTALMENT':2,\
    'NUM_UNPAID_LOANS': 2})
grouped

grouped.isna().sum()

mask=grouped[grouped['MEAN_PAYMENT'].isna()].index
grouped=grouped.drop(mask, axis=0)

# Create new CSV file:
grouped.to_csv('./csv/df_inst.csv', index=True)